mutate(
age = replace_na(age, median(age, na.rm = TRUE)),
total_payments = replace_na(total_payments, median(total_payments, na.rm = TRUE)),
across(where(is.character), ~replace_na(., get_mode(.)))
)
# 6. Strict Outlier Handling (IQR Method)
Q1  <- quantile(df_imputed$total_payments, 0.25, na.rm = TRUE)
Q3  <- quantile(df_imputed$total_payments, 0.75, na.rm = TRUE)
IQR_val <- Q3 - Q1
df_filtered <- df_imputed %>%
filter(total_payments >= (Q1 - 1.5 * IQR_val) &
total_payments <= (Q3 + 1.5 * IQR_val)) %>%
filter(total_payments < 10000) # Final safety check
# 7. FINAL STEP: Remove Student Duplicates
# We ensure one name (First + Last) only exists once in the file
df_final <- df_filtered %>%
arrange(student_id) %>%
distinct(first_name, last_name, .keep_all = TRUE)
# 8. Export
write_csv(df_final, output_file)
print(paste("Final Cleaned Data saved to:", output_file))
print(paste("Original rows:", nrow(df), "| Final rows:", nrow(df_final)))
summary(df_final)
library(tidyverse)
library(janitor)
# 1. Setup paths
folder_path <- "C:/Users/hiday/Documents/DS_TEB2043/PROJECT 1/"
input_file  <- paste0(folder_path, "Unclean Dataset.csv")
output_file <- paste0(folder_path, "Cleaned_Dataset_Perfect.csv")
# 2. Filter out "Hybrid" Junk Rows
raw_lines <- readLines(input_file, warn = FALSE)
valid_lines <- raw_lines[grepl("\\|", raw_lines) | seq_along(raw_lines) == 1]
col_names <- c("student_id", "first_name", "last_name", "age",
"gender", "course", "enrollment_date", "total_payments")
# 3. Load valid data
df <- read_delim(paste(valid_lines, collapse = "\n"),
delim = "|",
skip = 1,
col_names = col_names,
trim_ws = TRUE)
# 4. Initial Data Cleaning & Type Conversion
df_cleaned <- df %>%
mutate(
# Fix scientific notation by extracting only the first number block
total_payments = str_extract(total_payments, "[0-9.]+"),
total_payments = as.numeric(total_payments),
student_id = as.numeric(student_id),
age = as.numeric(age),
enrollment_date = as.Date(enrollment_date, format = "%Y-%m-%d"),
# Trim extra spaces from text columns
across(where(is.character), str_trim)
) %>%
filter(!is.na(student_id)) %>%
mutate(student_id = as.integer(student_id))
# 5. Standardization of Categories
# This fixes "Machine Learnin" vs "Machine Learning", etc.
df_standardized <- df_cleaned %>%
mutate(course = case_when(
str_detect(course, "Machine") ~ "Machine Learning",
str_detect(course, "Web")     ~ "Web Development",
str_detect(course, "Data Science") ~ "Data Science",
str_detect(course, "Data Anal")    ~ "Data Analysis",
str_detect(course, "Cyber")   ~ "Cyber Security",
TRUE ~ course
))
# 6. Handle Missing Values
get_mode <- function(v) {
uniqv <- unique(na.omit(v))
if(length(uniqv) == 0) return("Unknown")
uniqv[which.max(tabulate(match(v, uniqv)))]
}
df_imputed <- df_standardized %>%
mutate(
age = replace_na(age, median(age, na.rm = TRUE)),
total_payments = replace_na(total_payments, median(total_payments, na.rm = TRUE)),
across(where(is.character), ~replace_na(., get_mode(.)))
)
# 7. Outlier Handling (IQR Method)
Q1  <- quantile(df_imputed$total_payments, 0.25, na.rm = TRUE)
Q3  <- quantile(df_imputed$total_payments, 0.75, na.rm = TRUE)
IQR_val <- Q3 - Q1
df_no_outliers <- df_imputed %>%
filter(total_payments >= (Q1 - 1.5 * IQR_val) &
total_payments <= (Q3 + 1.5 * IQR_val)) %>%
filter(total_payments < 10000)
# 8. FINAL STEP: Ensure Unique Student IDs (Primary Key)
# This removes rows where different names were assigned to the same ID
df_perfect <- df_no_outliers %>%
arrange(student_id) %>%
distinct(student_id, .keep_all = TRUE)
# 9. Export the result
write_csv(df_perfect, output_file)
# Summary of cleaning
print("SUCCESS: Data is perfectly cleaned.")
print(paste("Rows remaining:", nrow(df_perfect)))
summary(df_perfect)
library(tidyverse)
library(janitor)
# 1. Setup paths
folder_path <- "C:/Users/hiday/Documents/DS_TEB2043/PROJECT 1/"
input_file  <- paste0(folder_path, "Unclean Dataset.csv")
output_file <- paste0(folder_path, "Cleaned_Dataset_Perfect.csv")
# 2. Filter out "Hybrid" Junk Rows
raw_lines <- readLines(input_file, warn = FALSE)
valid_lines <- raw_lines[grepl("\\|", raw_lines) | seq_along(raw_lines) == 1]
col_names <- c("student_id", "first_name", "last_name", "age",
"gender", "course", "enrollment_date", "total_payments")
# 3. Load valid data
df <- read_delim(paste(valid_lines, collapse = "\n"),
delim = "|",
skip = 1,
col_names = col_names,
trim_ws = TRUE)
# 4. Initial Data Cleaning & Type Conversion
df_cleaned <- df %>%
mutate(
# Fix scientific notation by extracting only the first number block
total_payments = str_extract(total_payments, "[0-9.]+"),
total_payments = as.numeric(total_payments),
student_id = as.numeric(student_id),
age = as.numeric(age),
enrollment_date = as.Date(enrollment_date, format = "%Y-%m-%d"),
# Trim extra spaces from text columns
across(where(is.character), str_trim)
) %>%
filter(!is.na(student_id)) %>%
mutate(student_id = as.integer(student_id))
# 5. Standardization of Categories
# This fixes "Machine Learnin" vs "Machine Learning", etc.
df_standardized <- df_cleaned %>%
mutate(course = case_when(
str_detect(course, "Machine") ~ "Machine Learning",
str_detect(course, "Web")     ~ "Web Development",
str_detect(course, "Data Science") ~ "Data Science",
str_detect(course, "Data Anal")    ~ "Data Analysis",
str_detect(course, "Cyber")   ~ "Cyber Security",
TRUE ~ course
))
# 6. Handle Missing Values
get_mode <- function(v) {
uniqv <- unique(na.omit(v))
if(length(uniqv) == 0) return("Unknown")
uniqv[which.max(tabulate(match(v, uniqv)))]
}
df_imputed <- df_standardized %>%
mutate(
age = replace_na(age, median(age, na.rm = TRUE)),
total_payments = replace_na(total_payments, median(total_payments, na.rm = TRUE)),
across(where(is.character), ~replace_na(., get_mode(.)))
)
# 7. Outlier Handling (IQR Method)
Q1  <- quantile(df_imputed$total_payments, 0.25, na.rm = TRUE)
Q3  <- quantile(df_imputed$total_payments, 0.75, na.rm = TRUE)
IQR_val <- Q3 - Q1
df_no_outliers <- df_imputed %>%
filter(total_payments >= (Q1 - 1.5 * IQR_val) &
total_payments <= (Q3 + 1.5 * IQR_val)) %>%
filter(total_payments < 10000)
# 8. FINAL STEP: Ensure Unique Student IDs (Primary Key)
# This removes rows where different names were assigned to the same ID
df_perfect <- df_no_outliers %>%
distinct(student_id, .keep_all = TRUE)%>%
# 2. Keep only one record per unique name (fixes David Davis/Sarah Brown issues)
distinct(first_name, last_name, .keep_all = TRUE) %>%
arrange(student_id)
# 9. Export the result
write_csv(df_perfect, output_file)
# Summary of cleaning
print("SUCCESS: Data is perfectly cleaned.")
print(paste("Rows remaining:", nrow(df_perfect)))
summary(df_perfect)
library(tidyverse)
library(janitor)
#SETUP PATH
file_path <- "C:/Users/hiday/Documents/DS_TEB2043/PROJECT 1/"
uncleaned <- paste0(file_path,"Unclean Dataset.csv")
#add new cleaned data files in the same path
cleaned<- paste0(file_path,"Cleaned Dataset.csv")
#REMOVE JUNK ROWS
#read file line by line
raw_lines <- readLines(uncleaned, warn = FALSE)
#ensure only proper formatted row remains
valid_lines <- raw_lines[grepl("\\|", raw_lines) | seq_along(raw_lines) == 1]
#ASSIGN COLUMN NAMES (MANUALLY)
col_names <- c("student_id", "first_name", "last_name", "age",
"gender", "course", "enrollment_date", "total_payments")
#LOAD VALID DATA "|" as separator
df <- read_delim(paste(valid_lines, collapse = "\n"),
delim = "|",
skip = 1,
col_names = col_names,
trim_ws = TRUE)
#INITIAL DATA CLEANING & TYPE CONVERSION
df_cleaned <- df %>%
mutate(
# fix notation (ignore e and afterwards eg: 3.5e+03abc only extract 3500)
total_payments = str_extract(total_payments, "[0-9.]+"),
# convert column into correct data types
total_payments = as.numeric(total_payments),
student_id = as.numeric(student_id),
age = as.numeric(age),
enrollment_date = as.Date(enrollment_date, format = "%Y-%m-%d"),
# remove extra spaces
across(where(is.character), str_trim)
) %>%
#remove invalid ID (remove row where student id is missing)
filter(!is.na(student_id)) %>%
mutate(student_id = as.integer(student_id))
#TEXT CONSISTENCIES
#fix eg: "Machine Learnin" vs "Machine Learning"
df_standardized <- df_cleaned %>%
mutate(course = case_when(
str_detect(course, "Machine") ~ "Machine Learning",
str_detect(course, "Web")     ~ "Web Development",
str_detect(course, "Data Science") ~ "Data Science",
str_detect(course, "Data Anal")    ~ "Data Analysis",
str_detect(course, "Cyber")   ~ "Cyber Security",
TRUE ~ course
))
#HANDLE MISSING VALUE
get_mode <- function(v) {
uniqv <- unique(na.omit(v))
if(length(uniqv) == 0) return("Unknown")
uniqv[which.max(tabulate(match(v, uniqv)))]
}
df_imputed <- df_standardized %>%
mutate(
age = replace_na(age, median(age, na.rm = TRUE)),
total_payments = replace_na(total_payments, median(total_payments, na.rm = TRUE)),
across(where(is.character), ~replace_na(., get_mode(.)))
)
#HANDLE OUTLIERS (USE IQR METHOD)
Q1  <- quantile(df_imputed$total_payments, 0.25, na.rm = TRUE)
Q3  <- quantile(df_imputed$total_payments, 0.75, na.rm = TRUE)
IQR_val <- Q3 - Q1
df_no_outliers <- df_imputed %>%
filter(total_payments >= (Q1 - 1.5 * IQR_val) &
total_payments <= (Q3 + 1.5 * IQR_val)) %>%
filter(total_payments < 100000) #removes extreme payment values
#REMOVE DUPLICATES
#removes rows where different names were assigned to the same ID
df_perfect <- df_no_outliers %>%
distinct(student_id, .keep_all = TRUE)%>%
#keep only one record per name
distinct(first_name, last_name, .keep_all = TRUE) %>%
arrange(student_id)
#EXPORT RESULT INTO CLEANED DATASET.CSV
write_csv(df_perfect, output_file)
#HANDLE OUTLIERS (USE IQR METHOD)
Q1  <- quantile(df_imputed$total_payments, 0.25, na.rm = TRUE)
Q3  <- quantile(df_imputed$total_payments, 0.75, na.rm = TRUE)
IQR_val <- Q3 - Q1
df_no_outliers <- df_imputed %>%
filter(total_payments >= (Q1 - 1.5 * IQR_val) &
total_payments <= (Q3 + 1.5 * IQR_val)) %>%
filter(total_payments < 100000) #removes extreme payment values
#REMOVE DUPLICATES
#removes rows where different names were assigned to the same ID
df_perfect <- df_no_outliers %>%
distinct(student_id, .keep_all = TRUE)%>%
#keep only one record per name
distinct(first_name, last_name, .keep_all = TRUE) %>%
arrange(student_id)
#EXPORT RESULT INTO CLEANED DATASET.CSV
write_csv(df_perfect, output_file)
#CHECK ERRORS
print("SUCCESS: Data is perfectly cleaned.")
print(paste("Rows remaining:", nrow(df_perfect)))
summary(df_perfect)
library(tidyverse)
library(janitor)
#SETUP PATH
file_path <- "C:/Users/hiday/Documents/DS_TEB2043/PROJECT 1/"
uncleaned <- paste0(file_path,"Unclean Dataset.csv")
#add new cleaned data files in the same path
cleaned<- paste0(file_path,"Cleaned Dataset.csv")
#REMOVE JUNK ROWS
#read file line by line
raw_lines <- readLines(uncleaned, warn = FALSE)
#ensure only proper formatted row remains
valid_lines <- raw_lines[grepl("\\|", raw_lines) | seq_along(raw_lines) == 1]
#ASSIGN COLUMN NAMES (MANUALLY)
col_names <- c("student_id", "first_name", "last_name", "age",
"gender", "course", "enrollment_date", "total_payments")
#LOAD VALID DATA "|" as separator
df <- read_delim(paste(valid_lines, collapse = "\n"),
delim = "|",
skip = 1,
col_names = col_names,
trim_ws = TRUE)
#INITIAL DATA CLEANING & TYPE CONVERSION
df_cleaned <- df %>%
mutate(
# fix notation (ignore e and afterwards eg: 3.5e+03abc only extract 3500)
total_payments = str_extract(total_payments, "[0-9.]+"),
# convert column into correct data types
total_payments = as.numeric(total_payments),
student_id = as.numeric(student_id),
age = as.numeric(age),
enrollment_date = as.Date(enrollment_date, format = "%Y-%m-%d"),
# remove extra spaces
across(where(is.character), str_trim)
) %>%
#remove invalid ID (remove row where student id is missing)
filter(!is.na(student_id)) %>%
mutate(student_id = as.integer(student_id))
#TEXT CONSISTENCIES
#fix eg: "Machine Learnin" vs "Machine Learning"
df_standardized <- df_cleaned %>%
mutate(course = case_when(
str_detect(course, "Machine") ~ "Machine Learning",
str_detect(course, "Web")     ~ "Web Development",
str_detect(course, "Data Science") ~ "Data Science",
str_detect(course, "Data Anal")    ~ "Data Analysis",
str_detect(course, "Cyber")   ~ "Cyber Security",
TRUE ~ course
))
#HANDLE MISSING VALUE
get_mode <- function(v) {
uniqv <- unique(na.omit(v))
if(length(uniqv) == 0) return("Unknown")
uniqv[which.max(tabulate(match(v, uniqv)))]
}
df_imputed <- df_standardized %>%
mutate(
age = replace_na(age, median(age, na.rm = TRUE)),
total_payments = replace_na(total_payments, median(total_payments, na.rm = TRUE)),
across(where(is.character), ~replace_na(., get_mode(.)))
)
#HANDLE OUTLIERS (USE IQR METHOD)
Q1  <- quantile(df_imputed$total_payments, 0.25, na.rm = TRUE)
Q3  <- quantile(df_imputed$total_payments, 0.75, na.rm = TRUE)
IQR_val <- Q3 - Q1
df_no_outliers <- df_imputed %>%
filter(total_payments >= (Q1 - 1.5 * IQR_val) &
total_payments <= (Q3 + 1.5 * IQR_val)) %>%
filter(total_payments < 100000) #removes extreme payment values
#REMOVE DUPLICATES
#removes rows where different names were assigned to the same ID
df_perfect <- df_no_outliers %>%
distinct(student_id, .keep_all = TRUE)%>%
#keep only one record per name
distinct(first_name, last_name, .keep_all = TRUE) %>%
arrange(student_id)
#EXPORT RESULT INTO CLEANED DATASET.CSV
write_csv(df_perfect, output_file)
#CHECK ERRORS
print("SUCCESS: Data is perfectly cleaned.")
print(paste("Rows remaining:", nrow(df_perfect)))
summary(df_perfect)
library(tidyverse)
library(janitor)
#SETUP PATH
file_path <- "C:/Users/hiday/Documents/DS_TEB2043/PROJECT 1/"
uncleaned <- paste0(file_path,"Unclean Dataset.csv")
#add new cleaned data files in the same path
cleaned<- paste0(file_path,"Cleaned Dataset.csv")
#REMOVE JUNK ROWS
#read file line by line
raw_lines <- readLines(uncleaned, warn = FALSE)
#ensure only proper formatted row remains
valid_lines <- raw_lines[grepl("\\|", raw_lines) | seq_along(raw_lines) == 1]
#ASSIGN COLUMN NAMES (MANUALLY)
col_names <- c("student_id", "first_name", "last_name", "age",
"gender", "course", "enrollment_date", "total_payments")
#LOAD VALID DATA "|" as separator
df <- read_delim(paste(valid_lines, collapse = "\n"),
delim = "|",
skip = 1,
col_names = col_names,
trim_ws = TRUE)
#INITIAL DATA CLEANING & TYPE CONVERSION
df_cleaned <- df %>%
mutate(
# fix notation (ignore e and afterwards eg: 3.5e+03abc only extract 3500)
total_payments = str_extract(total_payments, "[0-9.]+"),
# convert column into correct data types
total_payments = as.numeric(total_payments),
student_id = as.numeric(student_id),
age = as.numeric(age),
enrollment_date = as.Date(enrollment_date, format = "%Y-%m-%d"),
# remove extra spaces
across(where(is.character), str_trim)
) %>%
#remove invalid ID (remove row where student id is missing)
filter(!is.na(student_id)) %>%
mutate(student_id = as.integer(student_id))
#TEXT CONSISTENCIES
#fix eg: "Machine Learnin" vs "Machine Learning"
df_standardized <- df_cleaned %>%
mutate(course = case_when(
str_detect(course, "Machine") ~ "Machine Learning",
str_detect(course, "Web")     ~ "Web Development",
str_detect(course, "Data Science") ~ "Data Science",
str_detect(course, "Data Anal")    ~ "Data Analysis",
str_detect(course, "Cyber")   ~ "Cyber Security",
TRUE ~ course
))
#HANDLE MISSING VALUE
get_mode <- function(v) {
uniqv <- unique(na.omit(v))
if(length(uniqv) == 0) return("Unknown")
uniqv[which.max(tabulate(match(v, uniqv)))]
}
df_imputed <- df_standardized %>%
mutate(
age = replace_na(age, median(age, na.rm = TRUE)),
total_payments = replace_na(total_payments, median(total_payments, na.rm = TRUE)),
across(where(is.character), ~replace_na(., get_mode(.)))
)
#HANDLE OUTLIERS (USE IQR METHOD)
Q1  <- quantile(df_imputed$total_payments, 0.25, na.rm = TRUE)
Q3  <- quantile(df_imputed$total_payments, 0.75, na.rm = TRUE)
IQR_val <- Q3 - Q1
df_no_outliers <- df_imputed %>%
filter(total_payments >= (Q1 - 1.5 * IQR_val) &
total_payments <= (Q3 + 1.5 * IQR_val)) %>%
filter(total_payments < 100000) #removes extreme payment values
#REMOVE DUPLICATES
#removes rows where different names were assigned to the same ID
df_perfect <- df_no_outliers %>%
distinct(student_id, .keep_all = TRUE)%>%
#keep only one record per name
distinct(first_name, last_name, .keep_all = TRUE) %>%
arrange(student_id)
#EXPORT RESULT INTO CLEANED DATASET.CSV
write_csv(df_perfect, output_file)
#CHECK ERRORS
print("SUCCESS: Data is perfectly cleaned.")
print(paste("Rows remaining:", nrow(df_perfect)))
summary(df_perfect)
library(tidyverse)
library(janitor)
#SETUP PATH
file_path <- "C:/Users/hiday/Documents/DS_TEB2043/PROJECT 1/"
uncleaned <- paste0(file_path,"Unclean Dataset.csv")
#add new cleaned data files in the same path
cleaned<- paste0(file_path,"Cleaned Dataset.csv")
#REMOVE JUNK ROWS
#read file line by line
raw_lines <- readLines(uncleaned, warn = FALSE)
#ensure only proper formatted row remains
valid_lines <- raw_lines[grepl("\\|", raw_lines) | seq_along(raw_lines) == 1]
#ASSIGN COLUMN NAMES (MANUALLY)
col_names <- c("student_id", "first_name", "last_name", "age",
"gender", "course", "enrollment_date", "total_payments")
#LOAD VALID DATA "|" as separator
df <- read_delim(paste(valid_lines, collapse = "\n"),
delim = "|",
skip = 1,
col_names = col_names,
trim_ws = TRUE)
#INITIAL DATA CLEANING & TYPE CONVERSION
df_cleaned <- df %>%
mutate(
# fix notation (ignore e and afterwards eg: 3.5e+03abc only extract 3500)
total_payments = str_extract(total_payments, "[0-9.]+"),
# convert column into correct data types
total_payments = as.numeric(total_payments),
student_id = as.numeric(student_id),
age = as.numeric(age),
enrollment_date = as.Date(enrollment_date, format = "%Y-%m-%d"),
# remove extra spaces
across(where(is.character), str_trim)
) %>%
#remove invalid ID (remove row where student id is missing)
filter(!is.na(student_id)) %>%
mutate(student_id = as.integer(student_id))
#TEXT CONSISTENCIES
#fix eg: "Machine Learnin" vs "Machine Learning"
df_standardized <- df_cleaned %>%
mutate(course = case_when(
str_detect(course, "Machine") ~ "Machine Learning",
str_detect(course, "Web")     ~ "Web Development",
str_detect(course, "Data Science") ~ "Data Science",
str_detect(course, "Data Anal")    ~ "Data Analysis",
str_detect(course, "Cyber")   ~ "Cyber Security",
TRUE ~ course
))
#HANDLE MISSING VALUE
get_mode <- function(v) {
uniqv <- unique(na.omit(v))
if(length(uniqv) == 0) return("Unknown")
uniqv[which.max(tabulate(match(v, uniqv)))]
}
df_imputed <- df_standardized %>%
mutate(
age = replace_na(age, median(age, na.rm = TRUE)),
total_payments = replace_na(total_payments, median(total_payments, na.rm = TRUE)),
across(where(is.character), ~replace_na(., get_mode(.)))
)
#HANDLE OUTLIERS (USE IQR METHOD)
Q1  <- quantile(df_imputed$total_payments, 0.25, na.rm = TRUE)
Q3  <- quantile(df_imputed$total_payments, 0.75, na.rm = TRUE)
IQR_val <- Q3 - Q1
df_no_outliers <- df_imputed %>%
filter(total_payments >= (Q1 - 1.5 * IQR_val) &
total_payments <= (Q3 + 1.5 * IQR_val)) %>%
filter(total_payments < 100000) #removes extreme payment values
#REMOVE DUPLICATES
#removes rows where different names were assigned to the same ID
df_perfect <- df_no_outliers %>%
distinct(student_id, .keep_all = TRUE)%>%
#keep only one record per name
distinct(first_name, last_name, .keep_all = TRUE) %>%
arrange(student_id)
#EXPORT RESULT INTO CLEANED DATASET.CSV
write_csv(df_perfect, cleaned)
#CHECK ERRORS
print("SUCCESS: Data is perfectly cleaned.")
print(paste("Rows remaining:", nrow(df_perfect)))
summary(df_perfect)
